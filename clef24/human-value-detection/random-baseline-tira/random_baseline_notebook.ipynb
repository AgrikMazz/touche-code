{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Random-Baseline model from ACL'22"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "import random\n",
    "\n",
    "runs_as_inference_server = os.environ.get('TIRA_INFERENCE_SERVER', None) is not None\n",
    "dataset_dir = os.environ.get('TIRA_INPUT_DIRECTORY', './dataset')\n",
    "output_dir = os.environ.get('TIRA_OUTPUT_DIRECTORY', './output')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "active_subtask = 1  # either 1 or 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "values = [ \"Self-direction: thought\", \"Self-direction: action\", \"Stimulation\", \"Hedonism\", \"Achievement\", \"Power: dominance\", \"Power: resources\", \"Face\", \"Security: personal\", \"Security: societal\", \"Tradition\", \"Conformity: rules\", \"Conformity: interpersonal\", \"Humility\", \"Benevolence: caring\", \"Benevolence: dependability\", \"Universalism: concern\", \"Universalism: nature\", \"Universalism: tolerance\" ]\n",
    "probabilities_resorted = [ 0.17, 0.26, 0.06, 0.04, 0.27, 0.09, 0.11, 0.07, 0.38, 0.31, 0.11, 0.23, 0.04, 0.08, 0.29, 0.15, 0.38, 0.07, 0.14 ]\n",
    "probabilities_attained = [ 0.5 for _ in range(len(values)) ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predict function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_subtask_1(input_list: List) -> List[Dict]:\n",
    "    return [{values[i]: 'attained' if random.random() <= probabilities_resorted[i] else 'none' for i in range(len(values))} for _ in input_list]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_subtask_2(input_list: List) -> List[Dict]:\n",
    "    return [{values[i]: 'attained' if random.random() <= probabilities_attained[i] else 'constrained' for i in range(len(values))} for _ in input_list]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compatibility function for running as inference server\n",
    "def predict(input_list: List) -> List[Dict]:\n",
    "    if not runs_as_inference_server:\n",
    "        print(f'Labeling {len(input_list)} instances under subtask {active_subtask}')\n",
    "\n",
    "    return predict_subtask_1(input_list) if active_subtask == 1 else predict_subtask_2(input_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification on TIRA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# \"instance\" is a dict with keys \"Text-ID\", \"Sentence\", and \"Text\"\n",
    "def labelInstances(instances: List[Dict]):\n",
    "   predictions = [{\"Text-ID\": instance[\"Text-ID\"], \"Sentence\": instance[\"Sentence\"], **labels} for instance, labels in zip(instances, predict(instances))]\n",
    "   return predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def writeRun(labels, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    field_names = [ \"Text-ID\", \"Sentence\" ] + values\n",
    "\n",
    "    print(\"Writing run file\")\n",
    "    output_file = os.path.join(output_dir, \"predictions.tsv\")\n",
    "\n",
    "    with open(output_file, \"w\") as runFile:\n",
    "        writer = csv.DictWriter(runFile, fieldnames = field_names, delimiter = \"\\t\")\n",
    "        writer.writeheader()\n",
    "        for row in labels:\n",
    "            writer.writerow(row)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not runs_as_inference_server:\n",
    "    input_file = os.path.join(dataset_dir, \"sentences.tsv\")\n",
    "    writeRun(labelInstances(pd.read_csv(input_file, sep='\\t', header=0, index_col=None).to_dict('records')), output_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
