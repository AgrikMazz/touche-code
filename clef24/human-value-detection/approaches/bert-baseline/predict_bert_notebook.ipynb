{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# BERT model from ACL'22"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import List\n",
    "from components.setup import (load_arguments_from_tsv, split_arguments, write_tsv_dataframe)\n",
    "from components.models_bert import (predict_bert_model, load_tokenizer, pre_load_saved_model, get_available_values_by_subtask)\n",
    "\n",
    "runs_as_inference_server = os.environ.get('TIRA_INFERENCE_SERVER', None) is not None\n",
    "dataset_dir = os.environ.get('TIRA_INPUT_DIRECTORY', './dataset')\n",
    "output_dir = os.environ.get('TIRA_OUTPUT_DIRECTORY', './output')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_dir = 'models/'\n",
    "tokenizer_dir = 'tokenizer/'\n",
    "subtask = os.environ.get('SUBTASK', \"1\")\n",
    "if subtask not in ['1', '2']:\n",
    "    print(f'Unknown subtask \"{subtask}\". Defaulting to subtask \"1\".')\n",
    "    subtask = \"1\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "load_tokenizer(tokenizer_dir)\n",
    "\n",
    "values = get_available_values_by_subtask(subtask=subtask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pre_load_saved_model(os.path.join(model_dir, f'bert_train_subtask_{subtask}'), values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predict function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict(input_list: List) -> List:\n",
    "    # expect list of simple premise-strings\n",
    "    df_predict = pd.DataFrame(input_list, columns=['Text'])\n",
    "\n",
    "    result = predict_bert_model(df_predict, os.path.join(model_dir, f'bert_train_subtask_{subtask}'), values)\n",
    "    result = np.clip(result, 0.0, 1.0)\n",
    "    if subtask == '2':\n",
    "        for base_value in get_available_values_by_subtask(subtask='1'):\n",
    "            value_attained = f'{base_value} attained'\n",
    "            value_constrained = f'{base_value} constrained'\n",
    "            for i in range(len(result)):\n",
    "                val_sum = result.loc[i, value_attained] + result.loc[i, value_constrained]\n",
    "                if val_sum > 1.0:\n",
    "                    modifier = 1.0 / val_sum\n",
    "                    result.loc[i, value_attained] = modifier * result.loc[i, value_attained]\n",
    "                    result.loc[i, value_constrained] = modifier * result.loc[i, value_constrained]\n",
    "\n",
    "    return result.to_dict('records')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification on TIRA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not runs_as_inference_server:\n",
    "    argument_filepath = os.path.join(dataset_dir, 'sentences.tsv')\n",
    "\n",
    "    # load arguments\n",
    "    df_arguments = load_arguments_from_tsv(argument_filepath)\n",
    "\n",
    "    # format dataset\n",
    "    _, _, df_test = split_arguments(df_arguments)\n",
    "\n",
    "    # predict with Bert model\n",
    "    df_prediction = df_test[['Text-ID', 'Sentence-ID']]\n",
    "    print(\"===> Bert: Predicting...\")\n",
    "    prediction_list = predict(df_test['Text'].tolist())  # call uniform predict function\n",
    "    df_prediction = pd.concat([df_prediction, pd.DataFrame.from_dict(prediction_list)], axis=1)\n",
    "\n",
    "    # write predictions\n",
    "    print(\"===> Writing predictions...\")\n",
    "    write_tsv_dataframe(os.path.join(output_dir, 'predictions.tsv'), df_prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
