{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Adam-Smith"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import logging\n",
    "from typing import List\n",
    "from components.data_modules.BertDataModule import BertDataset\n",
    "from components.interface_modules.load_ensemble_list import (load_ensemble_list)\n",
    "from components.interface_modules.transformer_local import (load_local_tokenizer)\n",
    "from components.models.BertFineTunerPl import BertFineTunerPl\n",
    "\n",
    "runs_as_inference_server = os.environ.get('TIRA_INFERENCE_SERVER', None) is not None\n",
    "dataset_dir = os.environ.get('TIRA_INPUT_DIRECTORY', './dataset')\n",
    "output_dir = os.environ.get('TIRA_OUTPUT_DIRECTORY', './output')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_model_dir = 'checkpoints/human_value_trained_models'\n",
    "\n",
    "_model_registry = {}\n",
    "_ensemble_threshold = 0.26\n",
    "\n",
    "_, _ensemble_list, _label_columns, NAME = load_ensemble_list(_model_dir, _ensemble_threshold)\n",
    "\n",
    "logging.info(f'Initializing with configuration: {NAME}')\n",
    "print(f'Initializing with configuration: {NAME}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for idx, elem in enumerate(_ensemble_list):\n",
    "    logging.debug(f\"Loading model {elem['MODEL_CHECKPOINT']}\")\n",
    "\n",
    "    PARAMS = elem[\"PARAMS\"]\n",
    "    TRAINED_MODEL = BertFineTunerPl.load_from_checkpoint(\n",
    "        elem[\"MODEL_CHECKPOINT\"],\n",
    "        params=PARAMS,\n",
    "        label_columns=_label_columns,\n",
    "        n_classes=len(_label_columns)\n",
    "    )\n",
    "    TRAINED_MODEL.eval()\n",
    "    TRAINED_MODEL.freeze()\n",
    "    TRAINED_MODEL = TRAINED_MODEL.to(device)\n",
    "    _model_registry[elem['MODEL_CHECKPOINT']] = TRAINED_MODEL\n",
    "\n",
    "    logging.debug(f\"With Tokenizer {PARAMS['MODEL_PATH']}\")\n",
    "    if PARAMS['MODEL_PATH'] not in _model_registry.keys():\n",
    "        TOKENIZER = load_local_tokenizer(PARAMS[\"MODEL_PATH\"])\n",
    "        _model_registry[PARAMS['MODEL_PATH']] = TOKENIZER"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predict function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _predict_unseen_data(trained_model, model_tokenizer, params, data):\n",
    "    silver_df_dataset = BertDataset(\n",
    "        data=data,\n",
    "        tokenizer=model_tokenizer,\n",
    "        max_token_count=params[\"MAX_TOKEN_COUNT\"],\n",
    "    )\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for item in silver_df_dataset:\n",
    "        _, prediction = trained_model(\n",
    "            item[\"input_ids\"].unsqueeze(dim=0).to(device),\n",
    "            item[\"attention_mask\"].unsqueeze(dim=0).to(device)\n",
    "        )\n",
    "        predictions.append(prediction.flatten())\n",
    "\n",
    "    predictions = torch.stack(predictions).detach().cpu()\n",
    "\n",
    "    return predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict(input_list: List) -> List:\n",
    "    data = pd.DataFrame(input_list, columns=['text'])\n",
    "\n",
    "    predictions = []\n",
    "    for idx, elem in enumerate(_ensemble_list):\n",
    "        logging.debug(f'Classifying with {elem[\"MODEL_CHECKPOINT\"]}')\n",
    "        TRAINED_MODEL = _model_registry[elem[\"MODEL_CHECKPOINT\"]]\n",
    "        PARAMS = elem[\"PARAMS\"]\n",
    "        TOKENIZER = _model_registry[PARAMS['MODEL_PATH']]\n",
    "        try:\n",
    "            pred = _predict_unseen_data(\n",
    "                trained_model=TRAINED_MODEL,\n",
    "                model_tokenizer=TOKENIZER,\n",
    "                params=PARAMS,\n",
    "                data=data\n",
    "            )\n",
    "            predictions.append(pred)\n",
    "        except BaseException as e:\n",
    "            logging.error(f'Exception while running model \\'{elem[\"MODEL_CHECKPOINT\"]}\\': {str(e)}')\n",
    "            return []\n",
    "\n",
    "    predictions = torch.stack(predictions).numpy()\n",
    "    predictions_avg = np.mean(predictions, axis=0)\n",
    "\n",
    "    upper, lower = 1, 0\n",
    "    y_pred = np.where(predictions_avg > _ensemble_threshold, upper, lower)\n",
    "\n",
    "    prediction_list = [{} for _ in input_list]\n",
    "    for idx, l_name in enumerate(_label_columns):\n",
    "        for i in range(len(prediction_list)):\n",
    "            prediction_list[i][l_name] = str(y_pred[i, idx])\n",
    "\n",
    "    return prediction_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification on TIRA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not runs_as_inference_server:\n",
    "    test_df_input = pd.read_csv(os.path.join(dataset_dir, 'arguments.tsv'), sep='\\t')\n",
    "\n",
    "    test_df_input[\"text\"] = test_df_input[\"Premise\"] + \" \" + test_df_input[\"Stance\"] + \" \" + test_df_input[\"Conclusion\"]\n",
    "    input_list = test_df_input[\"text\"].tolist()\n",
    "\n",
    "    print(f'Starting prediction of {len(input_list)} instances')\n",
    "    prediction_list = predict(input_list)\n",
    "\n",
    "    test_prediction_df = pd.concat([test_df_input[['Argument ID']], pd.DataFrame.from_dict(prediction_list)], axis=1)\n",
    "\n",
    "    prediction_file = os.path.join(output_dir, \"predictions.tsv\")\n",
    "    print(f'Writing prediction to: {prediction_file}')\n",
    "    test_prediction_df.to_csv(prediction_file, sep=\"\\t\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}